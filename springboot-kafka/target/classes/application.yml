# kafka
spring:
  application:
    name: kafka
  profiles:
    active: prod
  kafka:
    listener:
      # 消费端监听的topic不存在时，项目启动会报错(关掉)
      missing-topics-fatal: false
      #设置批量消费，batch为批量
      type: single
    # kafka服务器地址(可以多个)
    bootstrap-servers: runtimex.vip:9092
    consumer:
      # 指定一个默认的组名
      group-id: kafka2
      # 当kafka中没有初始offset或offset超出范围时将自动重置offset
      # earliest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
      # latest:当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
      # none:topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
      auto-offset-reset: earliest
      # key/value的反序列化
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      enable-auto-commit: false
      # 提交offset延时(接收到消息后多久提交offset)
     # auto-commit-interval: 80
      # 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
      session-timeout-ms: 10000
      # 批量消费每次最多消费多少条消息
      max-poll-records: 100
      #两次poll的时间间隔如果超过这个时间，则会将消费者踢出消费者组，将分区分配给别的消费者消费，触发rebalance
      properties:
        max.poll.interval.ms: 500000
locale:
  aop-class:
  basenames:
    - classpath:i18n/messages
    - classpath:i18n/validatorMessages
    - classpath:i18n/commonMessages

#什么时候会发生rebalance?
#1、订阅 Topic 的分区数发生变化。
#2、订阅的 Topic 个数发生变化。
#3、消费组内成员个数发生变化。例如有新的 consumer 实例加入该消费组或者离开组。
app:
  operate:
    log:
      enabled: true
      model: GLOBAL
      topic: operate_log
      receive:
        enabled: true
  logging:
    enabled: true
server:
  port: 8089
